# Sentencepiece Tokenizer

'''


$ python Sentencepiece_tokenizer \

    --input                   path of input data \
    --model_name              name of model \

optional arguments:
    --vocab_size              number of vocab size \
    --character_coverage      put float number between [0,1] \
    --model_type              type of model \


'''